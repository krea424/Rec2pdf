# ===============================================
# === ESEMPIO DI CONFIGURAZIONE PER IL BACKEND ==
# ===============================================
# Questo file serve come modello. Copialo in .env e inserisci le tue chiavi.

# -- Credenziali Supabase (con permessi di servizio) --
SUPABASE_URL="INSERISCI_IL_TUO_URL_SUPABASE"
SUPABASE_SERVICE_KEY="INSERISCI_LA_TUA_CHIAVE_SEGRETA_DI_SERVIZIO_SUPABASE"

# -- Chiavi API per i servizi di Intelligenza Artificiale --

# Chiave API di OpenAI (usata per l'embedding nella feature RAG multi-tenant
# e richiesta dallo script `npm run ingest -- --workspaceId=<id>`)
# Ottenibile da: https://platform.openai.com/api-keys
OPENAI_API_KEY="sk-..."

# Chiave API di Google Gemini (usata per la generazione del testo Markdown
# durante la pipeline RAG e dai prompt contestuali)
# Ottenibile da: https://ai.google.dev/
GEMINI_API_KEY="AIzaSy..."

# -- Provider AI predefiniti --
# Imposta questi valori per selezionare il provider di default usato dal backend.
# Valori disponibili: "gemini", "openai". Se vuoto vengono usati i fallback (gemini per il testo, openai per gli embedding).
AI_TEXT_PROVIDER="gemini"
AI_EMBEDDING_PROVIDER="openai"

# -- Token per Hugging Face (richiesto per la diarizzazione con WhisperX) --
# Ottenibile da: https://huggingface.co/settings/tokens
HUGGING_FACE_TOKEN="hf_..."

